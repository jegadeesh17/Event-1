{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jegadeesh17/Event-1/blob/main/capstone_Copy1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBFXQGKYUc4X",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "##### Jegadeesh 20MIS1173 Capstone Project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE7KNzPPVrVV"
      },
      "source": [
        "# Rice Leaf Image classification and Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TuLVP7vVLR3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1WtoaOHVrVh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras import layers, models, Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH2OWy18IObw"
      },
      "source": [
        "\n",
        "\n",
        "This project demonstrates how to classify images of rice leaf diseases and design a recommendation system. It uses a `tf.keras.Sequential` model with a cascading architecture and loads data using `tf.keras.utils.image_dataset_from_directory`. It demonstrates the following concepts:\n",
        "\n",
        "*   Splitting data into a 70:30 ratio for training and validation.\n",
        "*   Efficiently loading a dataset off disk.\n",
        "*   Data augmentation to expand the dataset size and improve model generalization.\n",
        "*   Implementing a cascading model architecture.\n",
        "*   Utilizing a pre-trained ResNet50 model as a base within the cascading model.\n",
        "*   Building a custom CNN model to complement the ResNet50 base.\n",
        "*   Designing a recommender system based on image classification results.\n",
        "\n",
        "This tutorial follows an advanced machine learning workflow:\n",
        "\n",
        "1.  Examine and understand the data.\n",
        "2.  Split the data into 70:30 ratio.\n",
        "3.  Build an input pipeline with data augmentation.\n",
        "4.  Build a cascading model:\n",
        "    *   ResNet50 (base model)\n",
        "    *   Custom CNN model\n",
        "5.  Train the model.\n",
        "6.  Test the model.\n",
        "7.  Design a recommendation system:\n",
        "    *   Use sample images to predict the class.\n",
        "    *   Provide recommendations for plant disease conditions.\n",
        "8.  Improve the model and the recommendation system"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPHx8-t-VrVo"
      },
      "source": [
        "This tutorial uses a dataset of about 5,392 photos of rice leaf images . The dataset contains four sub-directories, one per class:\n",
        "\n",
        "```\n",
        "Bacterialblight\n",
        "Blast\n",
        "Brownspot\n",
        "Tungro\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyDNn9MbIzfT"
      },
      "source": [
        "### Create a dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anqiK_AGI086"
      },
      "source": [
        "Define some parameters for the loader:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H74l2DoDI2XD"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFBhRrrEI49z"
      },
      "source": [
        "It's good practice to use a validation split when developing your model. Use 80% of the images for training and 20% for validation."
      ]
    },
    {
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Update the path to your training dataset\n",
        "train_ds = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/output/train', # Replace with the correct path\n",
        "    target_size=(180, 180),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',color_mode='rgb',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_ds = val_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/output/val', # Replace with the correct path\n",
        "    target_size=(180, 180),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_ds = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/output/test', # Replace with the correct path\n",
        "    target_size=(180, 180),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',\n",
        "    shuffle=False\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "vwVtgmGTn_LP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLQULyAvJC3X"
      },
      "source": [
        "You can find the class names in the `class_names` attribute on these datasets. These correspond to the directory names in alphabetical order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHAxkHX5JD3k"
      },
      "outputs": [],
      "source": [
        "class_indices = train_ds.class_indices\n",
        "class_names = list(class_indices.keys())\n",
        "print(class_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uoVvxSLJW9m"
      },
      "source": [
        "## Visualize the data\n",
        "\n",
        "Here are the first nine images from the training dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBmEA9c0JYes"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "images, labels = next(train_ds)  # Get the next batch of images and labels\n",
        "\n",
        "for i in range(min(10,len(train_ds))):  # Iterate through the first 9 images in the batch (or fewer if the batch has less than 9)\n",
        "    ax = plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow((images[i]*255).astype(\"uint8\"))  # Display the image\n",
        "    plt.title(class_names[labels[i].astype(int)])  # Set the title with the class name\n",
        "    plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M6BXtXFJdW0"
      },
      "source": [
        "You will pass these datasets to the Keras `Model.fit` method for training later in this tutorial. If you like, you can also manually iterate over the dataset and retrieve batches of images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-MfMoenJi8s"
      },
      "outputs": [],
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj4FrKxxJkoW"
      },
      "source": [
        "The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Dr0at41KcAU"
      },
      "source": [
        "## Configure the dataset for performance\n",
        "\n",
        "Make sure to use buffered prefetching, so you can yield data from disk without having I/O become blocking. These are two important methods you should use when loading data:\n",
        "\n",
        "- `Dataset.cache` keeps the images in memory after they're loaded off disk during the first epoch. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\n",
        "- `Dataset.prefetch` overlaps data preprocessing and model execution while training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOjJSm7DKoZA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def prepare_ds(ds, shuffle=False):\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(1000)\n",
        "    return ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "train_ds = tf.data.Dataset.from_generator(\n",
        "    lambda: train_ds,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
        "    )\n",
        ")\n",
        "\n",
        "val_ds = tf.data.Dataset.from_generator(\n",
        "    lambda: val_ds,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
        "    )\n",
        ")\n",
        "\n",
        "test_ds = tf.data.Dataset.from_generator(\n",
        "    lambda: test_ds,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
        "    )\n",
        ")\n",
        "\n",
        "train_ds = prepare_ds(train_ds, shuffle=True)\n",
        "val_ds = prepare_ds(val_ds)\n",
        "test_ds = prepare_ds(test_ds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GUnmPF4JvEf"
      },
      "source": [
        "## Standardize the data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e56VXHMWJxYT"
      },
      "source": [
        "The RGB channel values are in the `[0, 255]` range. This is not ideal for a neural network; in general you should seek to make your input values small.\n",
        "\n",
        "Here, you will standardize values to be in the `[0, 1]` range by using `tf.keras.layers.Rescaling`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEYxo2CTJvY9"
      },
      "outputs": [],
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsRk1xCwKZR4"
      },
      "source": [
        "Note: We previously resized images using the `image_size` argument of `tf.keras.utils.image_dataset_from_directory`. If we want to include the resizing logic in your model as well, we can use the `tf.keras.layers.Resizing` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyFKdQpXMJT4"
      },
      "source": [
        "## Visualize training results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFvOvmAmMK9w"
      },
      "source": [
        "Creating plots of the loss and accuracy on the training and validation sets:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO_jT7HwMrEn"
      },
      "source": [
        "The plots show that training accuracy and validation accuracy are off by large margins, and the model has achieved only around 60% accuracy on the validation set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqtyGodAMvNV"
      },
      "source": [
        "## Overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixsz9XFfMxcu"
      },
      "source": [
        "In the plots above, the training accuracy is increasing linearly over time, whereas validation accuracy stalls around 60% in the training process. Also, the difference in accuracy between training and validation accuracy is noticeable—a sign of [overfitting](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit).\n",
        "\n",
        "When there are a small number of training examples, the model sometimes learns from noises or unwanted details from training examples—to an extent that it negatively impacts the performance of the model on new examples. This phenomenon is known as overfitting. It means that the model will have a difficult time generalizing on a new dataset.\n",
        "\n",
        "There are multiple ways to fight overfitting in the training process. In this tutorial, We'll use *data augmentation* and add *dropout* to our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDMfYqwmM1C-"
      },
      "source": [
        "## Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxYwix81M2YO"
      },
      "source": [
        "Overfitting generally occurs when there are a small number of training examples. [Data augmentation](./data_augmentation.ipynb) takes the approach of generating additional training data from your existing examples by augmenting them using random transformations that yield believable-looking images. This helps expose the model to more aspects of the data and generalize better.\n",
        "\n",
        "You will implement data augmentation using the following Keras preprocessing layers: `tf.keras.layers.RandomFlip`, `tf.keras.layers.RandomRotation`, and `tf.keras.layers.RandomZoom`. These can be included inside our model like other layers, and run on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9J80BAbIMs21"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Assuming you have defined img_height and img_width\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "\n",
        "# Define the data augmentation pipeline\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\",\n",
        "                      input_shape=(img_height,\n",
        "                                   img_width,\n",
        "                                   3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN4k1dK3S6eV"
      },
      "source": [
        "We Visualize a few augmented examples by applying data augmentation to the same image several times:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j30F69T4sIVN",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "Training the model for 10 epochs with the Keras `Model.fit` method:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeD3bXepYKXs"
      },
      "source": [
        "## Dropout\n",
        "\n",
        "Another technique to reduce overfitting is to introduce [dropout](https://developers.google.com/machine-learning/glossary#dropout_regularization) regularization to the network.\n",
        "\n",
        "When we apply dropout to a layer, it randomly drops out (by setting the activation to zero) a number of output units from the layer during the training process. Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This means dropping out 10%, 20% or 40% of the output units randomly from the applied layer.\n",
        "\n",
        "Create a new neural network with `tf.keras.layers.Dropout` before training it using the augmented images:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiYHcbvaL9H-"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku8L4TVBIOcK"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers, Input\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Define class names\n",
        "class_names = ['Bacterialblight', 'Blast', 'Brownspot', 'Tungro']\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# ================== Enhanced Data Pipeline ==================\n",
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    shear_range=0.15,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input\n",
        ")\n",
        "\n",
        "# Load datasets (ensure paths are correct)\n",
        "train_ds = train_datagen.flow_from_directory(\n",
        "   '/content/drive/MyDrive/output/train',\n",
        "    target_size=(180, 180),\n",
        "    batch_size=16,  # Reduced batch size for better stability\n",
        "    class_mode='sparse'\n",
        ")\n",
        "\n",
        "val_ds = val_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/output/val',\n",
        "    target_size=(180, 180),\n",
        "    batch_size=16,\n",
        "    class_mode='sparse'\n",
        ")\n",
        "\n",
        "test_ds = val_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/output/test',\n",
        "    target_size=(180, 180),\n",
        "    batch_size=16,\n",
        "    class_mode='sparse',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "# Enhanced Model Architecture with Regularization\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(180, 180, 3))\n",
        "\n",
        "# Strategic Fine-tuning (reduced trainable layers)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "for layer in base_model.layers[-8:]:  # Reduced from 10 to 8 layers\n",
        "    layer.trainable = True\n",
        "\n",
        "# Added L2 Regularization and increased Dropout\n",
        "inputs = Input(shape=(180, 180, 3))\n",
        "x = base_model(inputs)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(512, kernel_regularizer='l2')(x)  # Added L2 regularization\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Dropout(0.5)(x)  # Increased dropout\n",
        "x = layers.Dense(256, kernel_regularizer='l2')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "outputs = layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "# Optimized Training Configuration\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)  # Reduced initial LR\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Enhanced Callbacks\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=5,  # Original was 6\n",
        "        min_delta=0.001,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "     keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,  # More aggressive reduction\n",
        "        patience=2,\n",
        "        min_lr=1e-6\n",
        "    )\n",
        "]\n",
        "\n",
        "# Model Training with Visualization\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=25,  # Increased ceiling but early stopping will intervene\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Visualization of Training Metrics\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Curves')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Curves')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_metrics.png')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Save the model directly to a folder in Google Drive\n",
        "model.save('/content/drive/My Drive/trained_model.keras')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation and testing"
      ],
      "metadata": {
        "id": "XrpP5oky9pbk"
      }
    },
    {
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns # Import the seaborn library\n",
        "\n",
        "# Load model and test data\n",
        "model = tf.keras.models.load_model('/content/drive/My Drive/trained_model.keras')\n",
        "\n",
        "# Assuming 'val_datagen' is your ImageDataGenerator for the test set\n",
        "test_ds = val_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/output/test',  # Replace with the correct path\n",
        "    target_size=(180, 180),\n",
        "    batch_size=16,\n",
        "    class_mode='sparse',\n",
        "    shuffle=False\n",
        ")\n",
        "# Evaluation\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(f\"\\nTest Accuracy: {test_acc:.2%}\")\n",
        "\n",
        "# Detailed Reporting\n",
        "y_true = test_ds.classes\n",
        "y_pred = np.argmax(model.predict(test_ds), axis=1)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "# Confusion Matrix Visualization\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names) # Now sns is defined and can be used\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "s_2ljgjtCCtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsjXCBLYYNs5"
      },
      "source": [
        "We will add data augmentation to your model before training in the next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaKFzz72Lqpg"
      },
      "source": [
        "### Compile the model\n",
        "\n",
        "For this tutorial, choose the `tf.keras.optimizers.Adam` optimizer and `tf.keras.losses.SparseCategoricalCrossentropy` loss function. To view training and validation accuracy for each training epoch, pass the `metrics` argument to `Model.compile`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lkdl8VsBbZOu"
      },
      "source": [
        "## Results\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-HZO3UpIOcZ"
      },
      "source": [
        "## This part is for classification and Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpeIa0-KIOca"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "def preprocess_image(img_path):\n",
        "    \"\"\"Preprocess the image for classification by resizing and normalizing it.\"\"\"\n",
        "    img = image.load_img(img_path, target_size=(180, 180))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return preprocess_input(img_array)\n",
        "\n",
        "def classify_disease(model, img_path, class_names):\n",
        "    \"\"\"Classify the disease using the provided pre-trained model.\"\"\"\n",
        "    img_array = preprocess_image(img_path)\n",
        "    predictions = model.predict(img_array)\n",
        "    confidence = np.max(predictions) * 100  # Convert to percentage\n",
        "    predicted_class = class_names[np.argmax(predictions)]\n",
        "    return predicted_class, confidence\n",
        "\n",
        "def analyze_severity(img_path):\n",
        "    \"\"\"Analyze disease severity based on color analysis in HSV space.\"\"\"\n",
        "    # Read and resize the image\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (180, 180))\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Define color ranges for infected areas (adjust these as needed)\n",
        "    lower_brown = np.array([10, 50, 50])\n",
        "    upper_brown = np.array([30, 255, 255])\n",
        "    lower_black = np.array([0, 0, 0])\n",
        "    upper_black = np.array([180, 255, 50])\n",
        "    lower_yellow = np.array([20, 100, 100])\n",
        "    upper_yellow = np.array([40, 255, 255])\n",
        "\n",
        "    # Create masks for infected areas\n",
        "    brown_mask = cv2.inRange(hsv, lower_brown, upper_brown)\n",
        "    black_mask = cv2.inRange(hsv, lower_black, upper_black)\n",
        "    yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
        "\n",
        "    # Combine masks\n",
        "    disease_mask = brown_mask + black_mask + yellow_mask\n",
        "\n",
        "    # Calculate severity percentage\n",
        "    total_pixels = img.shape[0] * img.shape[1]\n",
        "    infected_pixels = np.sum(disease_mask > 0)\n",
        "    severity_percentage = (infected_pixels / total_pixels) * 100\n",
        "\n",
        "    # Categorize severity\n",
        "    if severity_percentage < 20:\n",
        "        severity = \"Low\"\n",
        "    elif severity_percentage < 50:\n",
        "        severity = \"Medium\"\n",
        "    else:\n",
        "        severity = \"High\"\n",
        "\n",
        "    return severity, severity_percentage\n",
        "\n",
        "def get_disease_recommendations(disease, severity):\n",
        "    \"\"\"Provide recommendations based on disease and severity.\"\"\"\n",
        "    recommendations = {\n",
        "        \"Tungro\": {\n",
        "            \"Low\": [\"High humidity (>80%)\", \"Monitor fields regularly\", \"Early/Potential\"],\n",
        "            \"Medium\": [\"Temperature: 25-28°C\", \"Remove infected plants\", \"Developing\"],\n",
        "            \"High\": [\"Asynchronous planting\", \"Implement strict vector control\", \"Advanced\"]\n",
        "        },\n",
        "        \"Bacterialblight\": {\n",
        "            \"Low\": [\"High humidity (>80%)\", \"Use disease-free seeds\", \"Early/Potential\"],\n",
        "            \"Medium\": [\"Rainfall or irrigation\", \"Apply balanced fertilizers\", \"Developing\"],\n",
        "            \"High\": [\"Flooding conditions\", \"Use resistant varieties\", \"Advanced\"]\n",
        "        },\n",
        "        \"Blast\": {\n",
        "            \"Low\": [\"High humidity (>90%)\", \"Monitor fields regularly\", \"Early/Potential\"],\n",
        "            \"Medium\": [\"Cloudy skies\", \"Avoid excessive nitrogen\", \"Developing\"],\n",
        "            \"High\": [\"Drought stress\", \"Apply fungicides at boot stage\", \"Advanced\"]\n",
        "        },\n",
        "        \"Brownspot\": {\n",
        "            \"Low\": [\"High humidity (86-100%)\", \"Use certified seeds\", \"Early/Potential\"],\n",
        "            \"Medium\": [\"Prolonged leaf wetness\", \"Apply balanced fertilizers\", \"Developing\"],\n",
        "            \"High\": [\"Water stress\", \"Apply fungicides\", \"Advanced\"]\n",
        "        }\n",
        "    }\n",
        "    # Default response if disease or severity isn’t found\n",
        "    return recommendations.get(disease, {}).get(severity, [\"No data\", \"No data\", \"No data\"])\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    # Define class names for your model\n",
        "    class_names = ['Bacterialblight', 'Blast', 'Brownspot', 'Tungro']\n",
        "\n",
        "    # Specify your image path (update this to your image location)\n",
        "    img_path = '/content/training_metrics.png'\n",
        "\n",
        "    model = tf.keras.models.load_model('/content/drive/My Drive/trained_model.keras')\n",
        "    # Classify the disease\n",
        "    disease, confidence = classify_disease(model, img_path, class_names)\n",
        "\n",
        "    # Analyze severity\n",
        "    severity, severity_percentage = analyze_severity(img_path)\n",
        "\n",
        "    # Get recommendations\n",
        "    recommendations = get_disease_recommendations(disease, severity)\n",
        "\n",
        "    # Display results\n",
        "    print(f\"Predicted Disease: {disease} with confidence {confidence:.2f}%\")\n",
        "    print(f\"Severity: {severity}\")\n",
        "    print(f\"Affected Area: {severity_percentage:.2f}%\")\n",
        "    print(f\"Conditions favoring the disease: {recommendations[0]}\")\n",
        "    print(f\"Disease Stage: {recommendations[2]}\")\n",
        "    print(f\"Recommended Measures: {recommendations[1]}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}